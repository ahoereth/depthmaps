{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demo of the Make3D dataset\n",
    "http://make3d.cs.cornell.edu/data.html#make3d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from Make3D import train_pairs, test_pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize samples from the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "_, axis = plt.subplots(5, 2, figsize=(10,20))\n",
    "plt.tight_layout()\n",
    "for (rgb, d), (ax1, ax2) in zip(train_pairs[:10], axis):\n",
    "    ax1.axis('off'), ax2.axis('off')\n",
    "    ax1.imshow(rgb)\n",
    "    ax2.imshow(sp.misc.imresize(d, rgb.shape))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Take a naive convolutional network approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simplify dataset first\n",
    "- Convert to grayscale\n",
    "- Scale targets down so the convolutional network can use striding and so we do not need padding\n",
    "- Normalize values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data, train_targets = zip(*train_pairs)\n",
    "test_data, test_targets = zip(*test_pairs)\n",
    "\n",
    "def rgb2gray(rgb):\n",
    "    return np.dot(rgb[...,:3], [0.299, 0.587, 0.114])\n",
    "\n",
    "train_data = [rgb2gray(img)/255 - .5 for img in train_data]\n",
    "train_targets = [sp.misc.imresize(img, (47, 31))/255 - .5 for img in train_targets]\n",
    "test_data = [rgb2gray(img)/255 - .5 for img in test_data]\n",
    "test_targets = [sp.misc.imresize(img, (47, 31))/255 - .5 for img in test_targets]\n",
    "\n",
    "\n",
    "train_x, train_t = np.asarray(train_data), np.asarray(train_targets)\n",
    "test_x, test_t = np.asarray(test_data), np.asarray(test_targets)\n",
    "\n",
    "print('train input/target shapes', train_data[0].shape, train_targets[0].shape)\n",
    "print('train input min/max/ptp', np.min(train_data), np.max(train_data), np.ptp(train_data))\n",
    "print('train target min/max/ptp', np.min(train_targets), np.max(train_targets), np.ptp(train_targets))\n",
    "\n",
    "tuples = zip(train_x[:10], train_t[:10])\n",
    "fig, axis = plt.subplots(5, 2, figsize=(10,20))\n",
    "plt.tight_layout(), plt.gray()\n",
    "for (rgb, d), (ax1, ax2) in zip(tuples, axis):\n",
    "    ax1.axis('off'), ax2.axis('off')\n",
    "    ax1.imshow(rgb)\n",
    "    ax2.imshow(sp.misc.imresize(d, rgb.shape))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Tensorflow Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# MODEL\n",
    "x = tf.placeholder(tf.float32, (None, 128, 96))\n",
    "t = tf.placeholder(tf.float32, (None, 47, 31))\n",
    "\n",
    "x_ = tf.reshape(x, (-1, 128, 96, 1))\n",
    "net = tf.layers.conv2d(x_, filters=16, kernel_size=16, strides=2, activation=tf.nn.relu)\n",
    "net = tf.layers.conv2d(net, filters=16, kernel_size=8, strides=1, activation=tf.nn.relu)\n",
    "net = tf.layers.conv2d(net, filters=32, kernel_size=4, strides=1, activation=tf.nn.relu)\n",
    "net = tf.layers.conv2d(net, filters=1, kernel_size=1)\n",
    "\n",
    "y = tf.squeeze(net, axis=3)\n",
    "\n",
    "loss = tf.reduce_mean(tf.square(t - y))\n",
    "optimizer = tf.train.AdamOptimizer(0.0001).minimize(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train\n",
    "Regularily evaluate the loss on the test data and compute test predictions when done with training.\n",
    "\n",
    "**10000 epochs is nothing one wants to run on the CPU.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for i in range(10000 + 1):\n",
    "        batch = np.random.permutation(32)\n",
    "        batch_x, batch_t = train_x[batch], train_t[batch]\n",
    "        sess.run(optimizer, {x: batch_x, t: batch_t})\n",
    "        if i % 1000 == 0:\n",
    "            print(i, sess.run(loss, {x: test_x, t: test_t}))\n",
    "    test_p = sess.run(y, {x: test_x})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize results on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "triples = zip(test_x[:10], test_t[:10], test_p[:10])\n",
    "_, axis = plt.subplots(5, 3, figsize=(10,20))\n",
    "plt.tight_layout(), plt.gray()\n",
    "for (rgb, d, p), (ax1, ax2, ax3) in zip(triples, axis):\n",
    "    ax1.axis('off'), ax2.axis('off'), ax3.axis('off')\n",
    "    ax1.imshow(rgb)\n",
    "    ax2.imshow(sp.misc.imresize(d, rgb.shape))\n",
    "    ax3.imshow(sp.misc.imresize(p, rgb.shape))\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "depthmaps",
   "language": "python",
   "name": "depthmaps"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
